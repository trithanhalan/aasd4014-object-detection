{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Analysis\n",
    "## AASD 4014 Final Project - Group 6\n",
    "### Pascal VOC 2007 Person/Dog Detection Dataset\n",
    "\n",
    "**Team Members:**\n",
    "- Athul Mathai (101520716) - Data Engineer\n",
    "- Anjana Jayakumar (101567844) - ML Engineer  \n",
    "- Anu Sunny (101578581) - DevOps & Deployment\n",
    "- Devikaa Dinesh (101568031) - Report Writer\n",
    "- Saranya Shaji (101569858) - Software Engineer\n",
    "- Syed Mohamed Shakeel Syed Nizar Imam (101518452) - QA Engineer\n",
    "- Tri Thanh Alan Inder Kumar (101413004) - Project Manager\n",
    "- Ishika Fatwani (101494093) - UX Designer & Visualization Specialist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/app/src')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our custom utilities\n",
    "from utils import plot_class_distribution, ensure_dir, load_json\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "data_dir = Path('/app/data')\n",
    "images_dir = data_dir / 'images'\n",
    "labels_dir = data_dir / 'labels'\n",
    "\n",
    "# Load dataset statistics if available\n",
    "stats_file = data_dir / 'dataset_stats.json'\n",
    "if stats_file.exists():\n",
    "    stats = load_json(str(stats_file))\n",
    "    print(\"Dataset Statistics:\")\n",
    "    print(json.dumps(stats, indent=2))\n",
    "else:\n",
    "    print(\"Dataset statistics not found. Run dataset preparation first.\")\n",
    "    stats = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_class_distribution():\n",
    "    \"\"\"Analyze class distribution in train and validation sets\"\"\"\n",
    "    \n",
    "    distribution = {'train': {'person': 0, 'dog': 0, 'images': 0}, \n",
    "                   'val': {'person': 0, 'dog': 0, 'images': 0}}\n",
    "    \n",
    "    class_names = ['person', 'dog']\n",
    "    \n",
    "    for split in ['train', 'val']:\n",
    "        split_labels_dir = labels_dir / split\n",
    "        \n",
    "        if not split_labels_dir.exists():\n",
    "            print(f\"Labels directory not found: {split_labels_dir}\")\n",
    "            continue\n",
    "            \n",
    "        label_files = list(split_labels_dir.glob('*.txt'))\n",
    "        distribution[split]['images'] = len(label_files)\n",
    "        \n",
    "        for label_file in label_files:\n",
    "            with open(label_file, 'r') as f:\n",
    "                for line in f:\n",
    "                    if line.strip():\n",
    "                        class_id = int(line.split()[0])\n",
    "                        if class_id == 0:\n",
    "                            distribution[split]['person'] += 1\n",
    "                        elif class_id == 1:\n",
    "                            distribution[split]['dog'] += 1\n",
    "    \n",
    "    return distribution\n",
    "\n",
    "# Analyze distribution\n",
    "if (labels_dir / 'train').exists():\n",
    "    dist = analyze_class_distribution()\n",
    "    print(\"Class Distribution Analysis:\")\n",
    "    for split in ['train', 'val']:\n",
    "        print(f\"\\n{split.upper()} SET:\")\n",
    "        print(f\"  Images: {dist[split]['images']}\")\n",
    "        print(f\"  Person instances: {dist[split]['person']}\")\n",
    "        print(f\"  Dog instances: {dist[split]['dog']}\")\n",
    "        total_instances = dist[split]['person'] + dist[split]['dog']\n",
    "        if total_instances > 0:\n",
    "            print(f\"  Person ratio: {dist[split]['person']/total_instances:.2%}\")\n",
    "            print(f\"  Dog ratio: {dist[split]['dog']/total_instances:.2%}\")\n",
    "else:\n",
    "    print(\"Dataset not prepared yet. Run dataset preparation first.\")\n",
    "    dist = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "if dist:\n",
    "    plot_class_distribution(dist, '/app/results/plots/class_distribution.png')\n",
    "else:\n",
    "    print(\"No distribution data to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sample Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample_images(num_samples=6):\n",
    "    \"\"\"Display sample images with their annotations\"\"\"\n",
    "    \n",
    "    train_images_dir = images_dir / 'train'\n",
    "    train_labels_dir = labels_dir / 'train'\n",
    "    \n",
    "    if not train_images_dir.exists():\n",
    "        print(\"Training images not found. Run dataset preparation first.\")\n",
    "        return\n",
    "    \n",
    "    image_files = list(train_images_dir.glob('*.jpg'))[:num_samples]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"No image files found.\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    class_names = ['person', 'dog']\n",
    "    colors = [(255, 0, 0), (0, 255, 0)]  # Red for person, Green for dog\n",
    "    \n",
    "    for i, img_path in enumerate(image_files[:6]):\n",
    "        # Load image\n",
    "        image = cv2.imread(str(img_path))\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Load corresponding label\n",
    "        label_path = train_labels_dir / (img_path.stem + '.txt')\n",
    "        \n",
    "        if label_path.exists():\n",
    "            h, w = image.shape[:2]\n",
    "            \n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    if line.strip():\n",
    "                        parts = line.strip().split()\n",
    "                        class_id = int(parts[0])\n",
    "                        x_center, y_center, width, height = map(float, parts[1:5])\n",
    "                        \n",
    "                        # Convert YOLO format to pixel coordinates\n",
    "                        x1 = int((x_center - width/2) * w)\n",
    "                        y1 = int((y_center - height/2) * h)\n",
    "                        x2 = int((x_center + width/2) * w)\n",
    "                        y2 = int((y_center + height/2) * h)\n",
    "                        \n",
    "                        # Draw bounding box\n",
    "                        color = colors[class_id]\n",
    "                        cv2.rectangle(image_rgb, (x1, y1), (x2, y2), color, 2)\n",
    "                        \n",
    "                        # Add label\n",
    "                        label = class_names[class_id]\n",
    "                        cv2.putText(image_rgb, label, (x1, y1-10), \n",
    "                                  cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "        \n",
    "        axes[i].imshow(image_rgb)\n",
    "        axes[i].set_title(f'Sample {i+1}: {img_path.name}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/app/results/plots/sample_images.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Display sample images\n",
    "display_sample_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image Size Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_sizes(sample_size=100):\n",
    "    \"\"\"Analyze distribution of image sizes\"\"\"\n",
    "    \n",
    "    train_images_dir = images_dir / 'train'\n",
    "    \n",
    "    if not train_images_dir.exists():\n",
    "        print(\"Training images not found.\")\n",
    "        return\n",
    "    \n",
    "    image_files = list(train_images_dir.glob('*.jpg'))[:sample_size]\n",
    "    \n",
    "    widths, heights, ratios = [], [], []\n",
    "    \n",
    "    for img_path in image_files:\n",
    "        with Image.open(img_path) as img:\n",
    "            w, h = img.size\n",
    "            widths.append(w)\n",
    "            heights.append(h)\n",
    "            ratios.append(w/h)\n",
    "    \n",
    "    if not widths:\n",
    "        print(\"No images to analyze.\")\n",
    "        return\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Width distribution\n",
    "    axes[0, 0].hist(widths, bins=20, alpha=0.7, color='skyblue')\n",
    "    axes[0, 0].set_title('Image Width Distribution')\n",
    "    axes[0, 0].set_xlabel('Width (pixels)')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    \n",
    "    # Height distribution\n",
    "    axes[0, 1].hist(heights, bins=20, alpha=0.7, color='lightcoral')\n",
    "    axes[0, 1].set_title('Image Height Distribution')\n",
    "    axes[0, 1].set_xlabel('Height (pixels)')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    \n",
    "    # Aspect ratio distribution\n",
    "    axes[1, 0].hist(ratios, bins=20, alpha=0.7, color='lightgreen')\n",
    "    axes[1, 0].set_title('Aspect Ratio Distribution')\n",
    "    axes[1, 0].set_xlabel('Width/Height Ratio')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    \n",
    "    # Scatter plot of width vs height\n",
    "    axes[1, 1].scatter(widths, heights, alpha=0.6, color='purple')\n",
    "    axes[1, 1].set_title('Width vs Height')\n",
    "    axes[1, 1].set_xlabel('Width (pixels)')\n",
    "    axes[1, 1].set_ylabel('Height (pixels)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/app/results/plots/image_size_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\nImage Size Statistics (n={len(widths)}):\")\n",
    "    print(f\"Width - Mean: {np.mean(widths):.1f}, Std: {np.std(widths):.1f}, Range: {min(widths)}-{max(widths)}\")\n",
    "    print(f\"Height - Mean: {np.mean(heights):.1f}, Std: {np.std(heights):.1f}, Range: {min(heights)}-{max(heights)}\")\n",
    "    print(f\"Aspect Ratio - Mean: {np.mean(ratios):.2f}, Std: {np.std(ratios):.2f}\")\n",
    "\n",
    "# Analyze image sizes\n",
    "analyze_image_sizes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bounding Box Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_bounding_boxes():\n",
    "    \"\"\"Analyze bounding box sizes and distributions\"\"\"\n",
    "    \n",
    "    train_labels_dir = labels_dir / 'train'\n",
    "    \n",
    "    if not train_labels_dir.exists():\n",
    "        print(\"Training labels not found.\")\n",
    "        return\n",
    "    \n",
    "    bbox_data = {'person': {'widths': [], 'heights': [], 'areas': []},\n",
    "                'dog': {'widths': [], 'heights': [], 'areas': []}}\n",
    "    \n",
    "    class_names = ['person', 'dog']\n",
    "    \n",
    "    label_files = list(train_labels_dir.glob('*.txt'))\n",
    "    \n",
    "    for label_file in label_files:\n",
    "        with open(label_file, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    parts = line.strip().split()\n",
    "                    class_id = int(parts[0])\n",
    "                    _, _, width, height = map(float, parts[1:5])\n",
    "                    \n",
    "                    if class_id < len(class_names):\n",
    "                        class_name = class_names[class_id]\n",
    "                        bbox_data[class_name]['widths'].append(width)\n",
    "                        bbox_data[class_name]['heights'].append(height)\n",
    "                        bbox_data[class_name]['areas'].append(width * height)\n",
    "    \n",
    "    # Create visualizations\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    colors = ['skyblue', 'lightcoral']\n",
    "    \n",
    "    for i, class_name in enumerate(class_names):\n",
    "        if not bbox_data[class_name]['widths']:\n",
    "            continue\n",
    "            \n",
    "        # Width distribution\n",
    "        axes[i, 0].hist(bbox_data[class_name]['widths'], bins=20, \n",
    "                       alpha=0.7, color=colors[i], label=class_name)\n",
    "        axes[i, 0].set_title(f'{class_name.capitalize()} - Bbox Width Distribution')\n",
    "        axes[i, 0].set_xlabel('Normalized Width')\n",
    "        axes[i, 0].set_ylabel('Frequency')\n",
    "        \n",
    "        # Height distribution\n",
    "        axes[i, 1].hist(bbox_data[class_name]['heights'], bins=20, \n",
    "                       alpha=0.7, color=colors[i], label=class_name)\n",
    "        axes[i, 1].set_title(f'{class_name.capitalize()} - Bbox Height Distribution')\n",
    "        axes[i, 1].set_xlabel('Normalized Height')\n",
    "        axes[i, 1].set_ylabel('Frequency')\n",
    "        \n",
    "        # Area distribution\n",
    "        axes[i, 2].hist(bbox_data[class_name]['areas'], bins=20, \n",
    "                       alpha=0.7, color=colors[i], label=class_name)\n",
    "        axes[i, 2].set_title(f'{class_name.capitalize()} - Bbox Area Distribution')\n",
    "        axes[i, 2].set_xlabel('Normalized Area')\n",
    "        axes[i, 2].set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('/app/results/plots/bbox_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    for class_name in class_names:\n",
    "        if bbox_data[class_name]['widths']:\n",
    "            print(f\"\\n{class_name.upper()} Bounding Box Statistics:\")\n",
    "            print(f\"  Count: {len(bbox_data[class_name]['widths'])}\")\n",
    "            print(f\"  Width - Mean: {np.mean(bbox_data[class_name]['widths']):.3f}, \"\n",
    "                  f\"Std: {np.std(bbox_data[class_name]['widths']):.3f}\")\n",
    "            print(f\"  Height - Mean: {np.mean(bbox_data[class_name]['heights']):.3f}, \"\n",
    "                  f\"Std: {np.std(bbox_data[class_name]['heights']):.3f}\")\n",
    "            print(f\"  Area - Mean: {np.mean(bbox_data[class_name]['areas']):.3f}, \"\n",
    "                  f\"Std: {np.std(bbox_data[class_name]['areas']):.3f}\")\n",
    "\n",
    "# Analyze bounding boxes\n",
    "analyze_bounding_boxes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dataset Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if dist:\n",
    "    total_train_images = dist['train']['images']\n",
    "    total_val_images = dist['val']['images']\n",
    "    total_person = dist['train']['person'] + dist['val']['person']\n",
    "    total_dog = dist['train']['dog'] + dist['val']['dog']\n",
    "    \n",
    "    print(f\"Total Images: {total_train_images + total_val_images}\")\n",
    "    print(f\"  Training: {total_train_images}\")\n",
    "    print(f\"  Validation: {total_val_images}\")\n",
    "    print(f\"\\nTotal Instances: {total_person + total_dog}\")\n",
    "    print(f\"  Person: {total_person}\")\n",
    "    print(f\"  Dog: {total_dog}\")\n",
    "    \n",
    "    if total_person + total_dog > 0:\n",
    "        print(f\"\\nClass Balance:\")\n",
    "        print(f\"  Person: {total_person/(total_person + total_dog):.1%}\")\n",
    "        print(f\"  Dog: {total_dog/(total_person + total_dog):.1%}\")\n",
    "\n",
    "print(\"\\nRECOMMENDATIONS FOR TRAINING:\")\n",
    "print(\"-\" * 40)\n",
    "print(\"1. Image Size: Use 512x512 for training (good balance of detail and speed)\")\n",
    "print(\"2. Data Augmentation: Apply horizontal flips, mosaic, and color jittering\")\n",
    "print(\"3. Class Balance: Monitor for potential class imbalance during training\")\n",
    "print(\"4. Batch Size: Start with 16 and adjust based on available memory\")\n",
    "print(\"5. Transfer Learning: Use YOLOv5s pretrained weights for faster convergence\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save analysis summary\n",
    "analysis_summary = {\n",
    "    \"timestamp\": pd.Timestamp.now().isoformat(),\n",
    "    \"dataset\": \"Pascal VOC 2007 (person/dog subset)\",\n",
    "    \"analysis_type\": \"Exploratory Data Analysis\",\n",
    "    \"distribution\": dist if dist else {},\n",
    "    \"recommendations\": [\n",
    "        \"Use 512x512 input resolution\",\n",
    "        \"Apply data augmentation\",\n",
    "        \"Monitor class balance\",\n",
    "        \"Use transfer learning with YOLOv5s\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "ensure_dir('/app/results/analysis')\n",
    "with open('/app/results/analysis/eda_summary.json', 'w') as f:\n",
    "    json.dump(analysis_summary, f, indent=2)\n",
    "\n",
    "print(\"Analysis complete! Results saved to /app/results/analysis/\")\n",
    "print(\"Generated plots saved to /app/results/plots/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}